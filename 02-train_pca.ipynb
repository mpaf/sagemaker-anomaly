{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop user_id, lock_id from all pandas dataframes\n",
    "\n",
    "X_train = X_train.drop(['user_id', 'lock_id', 'access_granted', 'is_weekend', 'is_business_hours', 'access_level', 'failed_attempts', 'time_of_day'], axis=1)\n",
    "X_test = X_test.drop(['user_id', 'lock_id', 'access_granted', 'is_weekend', 'is_business_hours', 'access_level', 'failed_attempts', 'time_of_day'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%set_env MLFLOW_TRACKING_URI={mlflow_arn}\n",
    "%set_env MLFLOW_EXPERIMENT_NAME=anomaly-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def train_PCA(X_train, y_train, X_test, y_test):\n",
    "    import mlflow\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    with mlflow.start_run(run_name=\"training-pca\"):\n",
    "        # Initialize and train PCA\n",
    "        pca = PCA(n_components=0.95)\n",
    "        X_train_pca = pca.fit_transform(X_train)\n",
    "        X_test_pca = pca.transform(X_test)\n",
    "\n",
    "        # Log PCA components\n",
    "        print(f\"PCA n components: {pca.n_components_}\")\n",
    "        mlflow.log_metric(\"pca_components\", pca.n_components_)\n",
    "\n",
    "        # Train a simple classifier (e.g., Logistic Regression)\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        clf = LogisticRegression(random_state=42)\n",
    "        clf.fit(X_train_pca, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = clf.predict(X_test_pca)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # log confusion_matrix to figure and mlflow\n",
    "        fig, ax = plt.subplots()\n",
    "        # add legend to axes\n",
    "        plt.title('Confusion Matrix', pad=20, size=14)\n",
    "        s = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "        s.set(xlabel='Predicted', ylabel='Actual')\n",
    "\n",
    "        mlflow.log_figure(fig, \"confusion_matrix.png\")\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metrics({\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1,\n",
    "            \"roc_auc\": roc_auc\n",
    "        })\n",
    "\n",
    "        return pca, clf, X_train_pca, X_test_pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca, clf, X_train_pca, X_test_pca = train_PCA(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use my trained logistic regression model to predict whether a datapoint is an anomaly\n",
    "sample = X_test.iloc[22]\n",
    "result = y_test.iloc[22]\n",
    "print(f\"sample {sample} with result {result}\")\n",
    "\n",
    "pca_comp = pca.transform([sample])\n",
    "pred_prob = clf.predict(pca_comp)\n",
    "print(pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Visualization\n",
    "\n",
    "This section visualizes the results of Principal Component Analysis (PCA) applied to our dataset.\n",
    "\n",
    "## 1. Scatter Plot of Principal Components\n",
    "\n",
    "First, we'll create a scatter plot of the first two principal components to visualize how our data points are distributed in the reduced dimensional space.\n",
    "\n",
    "This plot helps us:\n",
    "\n",
    "- Visualize data clustering patterns\n",
    "- Identify potential outliers\n",
    "- Understand data distribution in reduced dimensions\n",
    "\n",
    "## 2. Explained Variance Ratio\n",
    "\n",
    "Next, we'll plot the cumulative explained variance ratio to understand how much information is retained by each principal component.\n",
    "\n",
    "This plot helps us:\n",
    "\n",
    "- Determine the optimal number of components to retain\n",
    "- Understand the trade-off between dimensionality reduction and information preservation\n",
    "- Identify the point of diminishing returns in adding more components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dimensions of the following array\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "X_train_pca.shape\n",
    "\n",
    "# Plot the PCA components of X_train_pca\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1])\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.title('PCA Components of X_train_pca')\n",
    "plt.show()\n",
    "# Plot the explained variance ratio of the PCA components\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance Ratio of PCA Components')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
