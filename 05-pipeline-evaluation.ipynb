{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Pipeline for K-Means Anomaly Detection\n",
    "\n",
    "This notebook implements an evaluation step for our K-Means clustering-based anomaly detection model. We'll assess the model's performance by analyzing the distances between data points and their assigned cluster centroids, using percentile-based thresholds to identify anomalies.\n",
    "\n",
    "### Distance-Based Anomaly Scoring\n",
    "- Calculate the Euclidean distance between each point and its assigned cluster centroid\n",
    "- Establish anomaly thresholds based on distance percentiles\n",
    "- Points with distances above the threshold are flagged as potential anomalies\n",
    "\n",
    "## Expected Outputs\n",
    "\n",
    "1. **Metric Reports**\n",
    "   - Overall model performance metrics\n",
    "   - Anomaly detection results\n",
    "\n",
    "2. **Visualizations**\n",
    "   - Confusion matrix\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "This evaluation pipeline helps validate the effectiveness of our K-Means clustering model for anomaly detection and provides insights for threshold tuning and model optimization.\n",
    "\n",
    "Use cases for anomaly detection:\n",
    "- Quality control in manufacturing\n",
    "- Network traffic analysis\n",
    "- System performance monitoring\n",
    "- Fraud detection\n",
    "- Outlier identification in sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker==2.227.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.workflow.function_step import step\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.parameters import ParameterFloat, ParameterInteger, ParameterBoolean, ParameterString\n",
    "from sagemaker.workflow.pipeline_definition_config import PipelineDefinitionConfig\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'pipelines'\n",
    "\n",
    "config_yaml = f\"\"\"\n",
    "SchemaVersion: '1.0'\n",
    "SageMaker:\n",
    "  PythonSDK:\n",
    "    Modules:\n",
    "      RemoteFunction:\n",
    "        # role arn is not required if in SageMaker Notebook instance or SageMaker Studio\n",
    "        # Uncomment the following line and replace with the right execution role if in a local IDE\n",
    "        # RoleArn: <replace the role arn here>\n",
    "        S3RootUri: s3://{bucket}/{prefix}\n",
    "        InstanceType: ml.m5.xlarge\n",
    "        Dependencies: ./requirements.txt\n",
    "        IncludeLocalWorkDir: true\n",
    "        PreExecutionCommands:\n",
    "        - \"sudo chmod -R 777 /opt/ml/model\"\n",
    "        CustomFileFilter:\n",
    "          IgnoreNamePatterns:\n",
    "          - \"data/*\"\n",
    "          - \"models/*\"\n",
    "          - \"*.ipynb\"\n",
    "          - \"__pycache__\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(config_yaml, file=open('config.yaml', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r\n",
    "\n",
    "env_variables={\n",
    "    'MLFLOW_TRACKING_URI': mlflow_arn,\n",
    "    'MLFLOW_EXPERIMENT_NAME': ExecutionVariables.PIPELINE_NAME,\n",
    "    'MLFLOW_RUN_NAME': ExecutionVariables.PIPELINE_EXECUTION_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./steps/evaluation.py\n",
    "import os\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "\n",
    "def evaluation(x_test, y_test, model, percentile=95, run_id=None):\n",
    "    # set mlflow experiment and server\n",
    "    mlflow.set_tracking_uri(os.environ['MLFLOW_TRACKING_URI'])\n",
    "    mlflow.set_experiment(os.environ['MLFLOW_EXPERIMENT_NAME'])\n",
    "\n",
    "    if not run_id:\n",
    "        current_experiment=dict(mlflow.get_experiment_by_name(os.environ['MLFLOW_EXPERIMENT_NAME']))\n",
    "        experiment_id=current_experiment['experiment_id']   \n",
    "        run = MlflowClient().create_run(experiment_id=experiment_id, run_name=os.environ['MLFLOW_RUN_NAME'])\n",
    "        run_id = run.info.run_id\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id) as run:\n",
    "        \n",
    "        with mlflow.start_run(run_name='evaluation', nested=True) as run:\n",
    "\n",
    "            mlflow.log_param(\"percentile\", percentile)\n",
    "            \n",
    "            test_pred = model.predict(x_test)\n",
    "            test_dist = model.transform(x_test)\n",
    "            y_test = y_test.reset_index(drop=True)\n",
    "            test_anomaly_indexes = y_test.loc[y_test==1].index.tolist()\n",
    "\n",
    "            dist_to_centroid = [dist_list[ind] for ind, dist_list in zip(test_pred, test_dist)]\n",
    "            threshold = np.percentile(dist_to_centroid, percentile)\n",
    "            print(f\"Threshold: {threshold}\")\n",
    "            # get max_values index above threshold\n",
    "            anomaly_idx = np.where(dist_to_centroid > threshold)[0]\n",
    "            y_pred = [1 if x in anomaly_idx else 0 for x in range(len(test_pred))]\n",
    "            print(f\"Detected anomalies {len(anomaly_idx)}\")\n",
    "            print(f\"Groundtruth anomalies {len(test_anomaly_indexes)}\")\n",
    "            print(f\"Anomalies detected matching groundtruth {len(np.intersect1d(anomaly_idx, test_anomaly_indexes))}\")\n",
    "            \n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            roc_auc = roc_auc_score(y_test, y_pred)\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            \n",
    "            mlflow.log_metric(\"accuracy\", accuracy)\n",
    "            mlflow.log_metric(\"precision\", precision)\n",
    "            mlflow.log_metric(\"recall\", recall)\n",
    "            mlflow.log_metric(\"f1\", f1)\n",
    "            mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "            # log confusion_matrix to figure and mlflow\n",
    "            fig, ax = plt.subplots()\n",
    "            # add legend to axes\n",
    "            plt.title('Confusion Matrix', pad=20, size=14)\n",
    "            s = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "            s.set(xlabel='Predicted', ylabel='Actual')\n",
    "\n",
    "            mlflow.log_figure(fig, \"confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "s3fs\n",
    "seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending SageMaker Pipeline with Evaluation Step\n",
    "\n",
    "This notebook extends our existing SageMaker pipeline by adding a crucial evaluation step for our K-Means anomaly detection model. The pipeline now consists of three main steps: preprocessing, training, and evaluation. The evaluation step takes the trained K-Means model and test data as inputs, computing distance-based anomaly scores using the specified percentile threshold. The pipeline parameters allow for flexible configuration of the evaluation criteria, including the percentile threshold for anomaly detection and the instance type for computation.\n",
    "\n",
    "The evaluation step is integrated seamlessly with the previous steps, using the preprocessed validation data and the trained model artifacts as inputs. The pipeline handles the data flow between steps, ensuring that the evaluation metrics are computed consistently and stored for later analysis. This modular approach allows for easy modification of the evaluation criteria and enables systematic comparison of different model versions. The evaluation results provide insights into the model's effectiveness at identifying anomalies and help in fine-tuning the anomaly detection thresholds for optimal performance in production scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SageMaker Pipeline\n",
    "from steps.preprocess import preprocess_data\n",
    "from steps.training_kmeans import train_kmeans\n",
    "from steps.evaluation import evaluation\n",
    "\n",
    "\n",
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()\n",
    "\n",
    "pipeline_name = f\"anomaly-detection-pipeline\"\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"training_instance_type\", default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "\n",
    "kmeans_nclusters = ParameterInteger(\n",
    "    name=\"kmeans_nclusters\", default_value=2\n",
    ")\n",
    "\n",
    "input_data_s3_uri = ParameterString(\n",
    "    name=\"input_data_s3_uri\", default_value=data_s3_uri\n",
    ")\n",
    "\n",
    "percentile = ParameterFloat(\n",
    "    name=\"percentile\", default_value=95.0\n",
    ")\n",
    "\n",
    "processing_step = step(\n",
    "    preprocess_data,\n",
    "    name=\"Preprocess\",\n",
    "    job_name_prefix=f\"{pipeline_name}-Preprocess\",\n",
    "    environment_variables=env_variables,\n",
    "    instance_type=training_instance_type)(input_data_s3_uri)\n",
    "\n",
    "training_step = step(\n",
    "    train_kmeans,\n",
    "    name=\"Train\",\n",
    "    job_name_prefix=f\"{pipeline_name}-Train\",\n",
    "    environment_variables=env_variables,\n",
    "    instance_type=training_instance_type)(processing_step[0], kmeans_nclusters, run_id=processing_step[4])\n",
    "\n",
    "evaluation_step = step(\n",
    "    evaluation,\n",
    "    name=\"Evaluation\",\n",
    "    job_name_prefix=f\"{pipeline_name}-Evaluation\",\n",
    "    environment_variables=env_variables,\n",
    "    instance_type=training_instance_type)(processing_step[1], processing_step[3], training_step[0], percentile=percentile, run_id=processing_step[4])\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        training_instance_type,\n",
    "        kmeans_nclusters,\n",
    "        input_data_s3_uri,\n",
    "        percentile\n",
    "    ],\n",
    "    steps=[processing_step, training_step, evaluation_step],\n",
    "    pipeline_definition_config=PipelineDefinitionConfig(use_custom_job_prefix=True),        \n",
    ")\n",
    "\n",
    "# Execute the pipeline in SageMaker\n",
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.start(\n",
    "    parameters={\n",
    "        \"input_data_s3_uri\": data_s3_uri,\n",
    "        \"kmeans_nclusters\": 2,\n",
    "        \"training_instance_type\": \"ml.m5.large\",\n",
    "        \"percentile\": 96\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
